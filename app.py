import streamlit as st # type: ignore
import time
from prompt import firePrompt  # Ensure prompt.py exists and firePrompt is defined

st.set_page_config(
    page_title='Tamil LLM',
    page_icon='ğŸ’ğŸ»â€â™‚ï¸',
    layout='wide',
    initial_sidebar_state='expanded'
)

# Initialize session state variables
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'temp' not in st.session_state:
    st.session_state.temp = 0.3  # Default temperature value

# Sidebar Configuration
with st.sidebar:
    st.markdown('## à®à®©à®¤à¯ à®•à®±à¯à®ªà®©à¯ˆ à®¤à®¿à®±à®©à¯ˆ à®¤à¯‡à®°à¯à®µà¯ à®šà¯†à®¯à¯à®• !', unsafe_allow_html=True)
    st.session_state.temp = st.slider(
        label='Temperature', min_value=0.0, max_value=1.0, step=0.1, value=st.session_state.temp
    )
    st.image('sidebar_logo.png', use_column_width=True)
    st.image('cit_logo_small.png', use_column_width=True)

# Function to get avatar based on role
def getAvatar(role):
    return "tamil-llama-logo2.png" if role == 'assistant' else "cit_logo_small.png"

# Function to build chat context
def getContext():
    return "\n".join(f"role: {msg['role']} content: {msg['content']}" for msg in st.session_state.messages[:-1])

# Header
st.markdown('# :rainbow[Local] ğŸ  :rainbow[Private] ğŸ”’ :rainbow[à®¤à®®à®¿à®´à¯ AI Assistant] ğŸ¤–', unsafe_allow_html=True)
st.markdown('## :rainbow[Powered by à®¤à®®à®¿à®´à¯ ğŸ¦™ğŸ¦™ğŸ¦™] ', unsafe_allow_html=True)

# Assistant's initial message
with st.chat_message(name="assistant", avatar='tamil-llama-logo2.png'):
    st.markdown('#### Ask me anything! à®à®©à¯à®©à®¿à®Ÿà®®à¯ à®¤à®®à®¿à®´à®¿à®²à¯à®®à¯ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à®¾à®®à¯! ğŸ™ğŸ»')

# Display previous messages
for message in st.session_state.messages:
    with st.chat_message(name=message["role"], avatar=getAvatar(message["role"])):
        st.markdown(f'{message["content"]}')

# User input handling
prompt = st.chat_input(placeholder="Chat with me. à®à®©à¯à®©à®¿à®Ÿà®®à¯ à®¤à®®à®¿à®´à®¿à®²à¯à®®à¯ à®‰à®°à¯ˆà®¯à®¾à®Ÿà®²à®¾à®®à¯!")
if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message(name="user", avatar='cit_logo_small.png'):
        st.markdown(prompt)
    
    with st.chat_message(name='assistant', avatar='tamil-llama-logo2.png'):
        message_placeholder = st.empty()
        full_response = ""
        
        with st.spinner(text="Thinking... ğŸ’­ğŸ’­ğŸ’­"):
            raw_response = firePrompt(prompt, temp=st.session_state.temp)
            response = str(raw_response)
            
            # Simulate response typing effect
            for chunk in response.split():
                full_response += chunk + " "
                time.sleep(0.05)
                message_placeholder.markdown(full_response + "â–Œ", unsafe_allow_html=True)
            
            message_placeholder.markdown(f'#### {full_response}', unsafe_allow_html=True)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
